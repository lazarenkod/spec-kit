# Parallel Agent Orchestration Instructions

> **For Claude Code**: This section instructs you how to execute subagents defined in `claude_code.subagents` using parallel Task tool calls.

## Overview

When this command defines `claude_code.subagents` in its YAML frontmatter, you MUST execute them using parallel Task tool calls organized into dependency waves.

## Ultrathink Mode Detection

**Activation**: Ultrathink mode is active when BOTH conditions are met:
```yaml
claude_code:
  reasoning_mode: extended      # REQUIRED for ultrathink
  thinking_budget: 8000         # REQUIRED (recommended: 8000-16000)
```

**Ultrathink Behavior**:
- Enables deep reasoning for complex architectural decisions
- Allocates extended thinking time for each subagent
- Uses opus model by default for high-stakes tasks
- Increases wave completion verification rigor

**Detection Logic**:
```text
IF claude_code.reasoning_mode == "extended" AND claude_code.thinking_budget >= 8000:
  ULTRATHINK_MODE = true
  DEFAULT_MODEL = claude_code.model OR "opus"
  LOG "âš¡ Ultrathink mode activated (budget: {thinking_budget})"
ELSE:
  ULTRATHINK_MODE = false
  DEFAULT_MODEL = "sonnet"
```

## Model Routing Guidelines

Select models based on task complexity and cost/performance tradeoffs:

| Model | Use For | Thinking Budget | Cost Factor |
|-------|---------|-----------------|-------------|
| **haiku** | Simple tasks: scaffolding, config files, dependency install, file copying | 2000-4000 | 1x (baseline) |
| **sonnet** | Standard tasks: data layer, API building, test generation, documentation | 4000-8000 | 10x |
| **opus** | Complex tasks: architecture decisions, business logic, multi-file refactoring | 8000-16000 | 25x |

**Model Selection by Role Group**:
```text
INFRA â†’ haiku (scaffolding, deps, config)
BACKEND â†’ sonnet/opus (data layer: sonnet, business logic: opus)
FRONTEND â†’ sonnet (UI components, state management)
TESTING â†’ sonnet (test generation, mocking)
REVIEW â†’ sonnet (code review, quality checks)
DOCS â†’ haiku (documentation generation)
```

**Override Priority**:
1. `subagent.model_override` (highest - explicit per-agent)
2. Adaptive routing matrix (complexity_tier Ã— role_group)
3. Role group default (from table above)
4. `claude_code.model` (command default)
5. "sonnet" (fallback)

---

## Adaptive Model Routing

> **Purpose**: Dynamically select the optimal model (haiku/sonnet/opus) for each subagent based on feature complexity and role group, reducing costs by 40-85% for simpler features.

### Step 0: Determine Complexity Tier

Execute BEFORE building waves. Analyze spec.md to determine feature complexity.

```text
FUNCTION determine_complexity_tier(FEATURE_DIR):

  spec_path = "{FEATURE_DIR}/spec.md"

  IF NOT exists(spec_path):
    LOG "âš ï¸ No spec.md found, defaulting to MODERATE"
    RETURN "MODERATE", 50

  # Count complexity signals
  spec_content = read(spec_path)

  user_story_count = count_pattern(spec_content, "### User Story")
  fr_count = count_pattern(spec_content, "FR-\d{3}")
  as_count = count_pattern(spec_content, "AS-\d")
  api_count = count_pattern(spec_content, "API-\d{3}|PKG-\d{3}")

  # Technical complexity signals
  tech_signals = count_keywords(spec_content, [
    "real-time", "distributed", "cache", "queue", "ML",
    "async", "websocket", "migration", "legacy"
  ])

  # Calculate score (0-100)
  score = 0
  score += min(25, user_story_count * 5)   # Max 25 from stories
  score += min(25, fr_count * 2)            # Max 25 from FRs
  score += min(25, api_count * 8)           # Max 25 from integrations
  score += min(25, tech_signals * 5)        # Max 25 from tech signals

  # Determine tier
  IF score <= 25:     tier = "TRIVIAL"
  ELIF score <= 50:   tier = "SIMPLE"
  ELIF score <= 75:   tier = "MODERATE"
  ELSE:               tier = "COMPLEX"

  LOG "ğŸ“Š Complexity: {tier} (score: {score}/100)"
  LOG "   Stories: {user_story_count}, FRs: {fr_count}, APIs: {api_count}"

  RETURN tier, score
```

### Step 0.5: Apply Model Routing Matrix

```text
MODEL_ROUTING_MATRIX = {
  "TRIVIAL": {
    "INFRA": "haiku", "BACKEND": "sonnet", "FRONTEND": "haiku",
    "TESTING": "haiku", "REVIEW": "haiku", "DOCS": "haiku"
  },
  "SIMPLE": {
    "INFRA": "haiku", "BACKEND": "sonnet", "FRONTEND": "sonnet",
    "TESTING": "haiku", "REVIEW": "sonnet", "DOCS": "haiku"
  },
  "MODERATE": {
    "INFRA": "haiku", "BACKEND": "opus", "FRONTEND": "sonnet",
    "TESTING": "sonnet", "REVIEW": "opus", "DOCS": "haiku"
  },
  "COMPLEX": {
    "INFRA": "sonnet", "BACKEND": "opus", "FRONTEND": "opus",
    "TESTING": "sonnet", "REVIEW": "opus", "DOCS": "sonnet"
  }
}

FUNCTION apply_model_routing(subagents, complexity_tier):

  assignments = {}

  FOR EACH agent IN subagents:

    # Priority 1: Explicit model_override (skip routing)
    IF agent.model_override IS SET:
      assignments[agent.role] = {model: agent.model_override, reason: "explicit"}
      CONTINUE

    # Priority 2: Matrix lookup by role_group
    role_group = agent.role_group OR "BACKEND"
    selected = MODEL_ROUTING_MATRIX[complexity_tier][role_group]
    agent.model_override = selected
    assignments[agent.role] = {model: selected, reason: "{complexity_tier}/{role_group}"}

  RETURN assignments
```

### Cost Report

Display after routing to show cost savings:

```text
FUNCTION report_routing(assignments, tier, score):

  COSTS = {haiku: 0.001, sonnet: 0.012, opus: 0.060}  # $/agent approx

  haiku_n = count(assignments WHERE model="haiku")
  sonnet_n = count(assignments WHERE model="sonnet")
  opus_n = count(assignments WHERE model="opus")

  adaptive_cost = haiku_n * COSTS.haiku + sonnet_n * COSTS.sonnet + opus_n * COSTS.opus
  opus_cost = len(assignments) * COSTS.opus
  savings = opus_cost - adaptive_cost
  savings_pct = (savings / opus_cost * 100) IF opus_cost > 0 ELSE 0

  PRINT "
ğŸ¯ Adaptive Model Routing
â”œâ”€â”€ Complexity: {tier} (score: {score}/100)
â”œâ”€â”€ Models: haiku({haiku_n}) sonnet({sonnet_n}) opus({opus_n})
â”œâ”€â”€ Assignments:"

  FOR role, a IN assignments:
    PRINT "â”‚   â””â”€â”€ {role}: {a.model} ({a.reason})"

  PRINT "â”œâ”€â”€ Cost: ${adaptive_cost:.3f} (vs ${opus_cost:.3f} all-opus)
â””â”€â”€ Savings: ${savings:.3f} ({savings_pct:.0f}%)
"
```

### Skip Flag

```text
IF "--no-adaptive-model" IN ARGS:
  LOG "âš¡ Adaptive routing DISABLED (using template defaults)"
  SKIP Step 0, Step 0.5
```

### Complexity Tier Reference

| Tier | Score | Typical Feature | Default Model Mix |
|------|-------|-----------------|-------------------|
| TRIVIAL | 0-25 | Bug fix, config change | 90% haiku, 10% sonnet |
| SIMPLE | 26-50 | Single component feature | 50% haiku, 40% sonnet, 10% opus |
| MODERATE | 51-75 | Multi-component feature | 30% haiku, 40% sonnet, 30% opus |
| COMPLEX | 76-100 | System-wide change | 10% haiku, 40% sonnet, 50% opus |

---

## Execution Algorithm

### Step 1: Parse Subagents

Extract all subagents from `claude_code.subagents` where `parallel: true`.

For each subagent, capture:
- `role` â€” unique identifier and Task description
- `prompt` â€” the task prompt (inject feature context)
- `depends_on` â€” list of role names that must complete first
- `priority` â€” lower number = higher priority (default: 5)
- `model_override` â€” optional model (haiku/sonnet/opus)
- `role_group` â€” grouping for parallel execution (INFRA, BACKEND, FRONTEND, TESTING, REVIEW)

### Step 2: Build Dependency Waves

Organize subagents into waves using topological sort:

```
Wave 1: Agents with depends_on = [] (no dependencies)
Wave 2: Agents whose depends_on are all in Wave 1
Wave 3: Agents whose depends_on are all in Waves 1-2
...and so on
```

**Constraints**:
- Maximum agents per wave: `orchestration.max_parallel` (default: 3)
- Within a wave, sort by `priority` (lower first)
- If wave exceeds max_parallel, split into sub-waves

### Step 3: Execute Each Wave

For each wave, launch ALL agents in a **SINGLE message** with multiple Task tool calls:

```
Wave 1 Execution:
â”œâ”€â”€ Task(role="project-scaffolder", ...)
â”œâ”€â”€ Task(role="dependency-installer", ...)
â””â”€â”€ Task(role="config-generator", ...)
    â†“ (all execute in parallel)
    â†“
[Wait for all Wave 1 agents to complete]
    â†“
Wave 2 Execution:
â”œâ”€â”€ Task(role="data-layer-builder", ...)
â”œâ”€â”€ Task(role="ui-foundation-builder", ...)
â””â”€â”€ Task(role="api-builder", ...)
```

**CRITICAL**: To achieve parallelism, ALL Task calls for a wave MUST be in the same response message. Separate messages execute sequentially.

### Step 4: Wave Overlap (Optional)

If `orchestration.wave_overlap.enabled: true`:
- Start Wave N+1 when Wave N reaches `overlap_threshold` (default: 80%)
- Use `run_in_background: true` for background execution
- Check completion with `TaskOutput` before proceeding

## Task Tool Call Pattern

For each subagent, construct a Task call:

```
Task(
  description: "{role}",
  prompt: "{expanded_prompt}",
  subagent_type: "general-purpose",
  model: "{model_override or 'sonnet'}"
)
```

### Prompt Expansion

Expand the subagent's `prompt` with feature context:

```
Feature: {FEATURE_DIR}
Spec: {FEATURE_DIR}/spec.md
Plan: {FEATURE_DIR}/plan.md
Tasks: {FEATURE_DIR}/tasks.md

{original subagent prompt}

Output your results clearly. Report any blockers or issues.
```

## Example: /speckit.implement

The implement command defines 10 subagents across 4 waves:

```yaml
subagents:
  # Wave 1: Infrastructure
  - role: project-scaffolder
    depends_on: []
    priority: 10

  - role: dependency-installer
    depends_on: [project-scaffolder]
    priority: 9

  # Wave 2: Core Implementation
  - role: data-layer-builder
    depends_on: [dependency-installer]
    role_group: BACKEND

  - role: ui-foundation-builder
    depends_on: [dependency-installer]
    role_group: FRONTEND

  - role: api-builder
    depends_on: [data-layer-builder]
    role_group: BACKEND

  - role: ui-feature-builder
    depends_on: [ui-foundation-builder, api-builder]
    role_group: FRONTEND

  # Wave 3: Testing
  - role: unit-test-generator
    depends_on: [data-layer-builder, api-builder]
    role_group: TESTING

  - role: integration-test-generator
    depends_on: [unit-test-generator]
    role_group: TESTING

  # Wave 4: Review
  - role: self-reviewer
    depends_on: [ui-feature-builder, integration-test-generator]
    role_group: REVIEW
```

**Wave Execution Plan**:
1. Wave 1: [project-scaffolder] â†’ then [dependency-installer]
2. Wave 2: [data-layer-builder, ui-foundation-builder] â†’ then [api-builder, ui-feature-builder]
3. Wave 3: [unit-test-generator] â†’ then [integration-test-generator]
4. Wave 4: [self-reviewer]

## Error Handling

**Fail-Fast Mode** (default when `orchestration.fail_fast: true`):
- If any agent in a wave fails, STOP execution
- Report the failure with agent name and error
- Do not proceed to next wave

**Continue Mode**:
- Log failed agents but continue with remaining
- Skip dependent agents whose dependencies failed
- Report all failures at the end

## Progress Reporting

After each wave completes, report:
```
Wave N/M completed:
  âœ“ {agent1}: {brief summary}
  âœ“ {agent2}: {brief summary}
  âœ— {agent3}: {error if failed}

Proceeding to Wave {N+1}...
```

## Dry Run Mode

When `--dry-run` flag is present, output the execution plan without running:

```
Parallel Execution Plan:
========================
Wave 1 (2 agents):
  - project-scaffolder [priority: 10, model: haiku]
  - config-generator [priority: 9, model: haiku]

Wave 2 (3 agents, max_parallel: 3):
  - data-layer-builder [depends: dependency-installer]
  - ui-foundation-builder [depends: dependency-installer]
  - api-builder [depends: data-layer-builder]

Total: 4 waves, 10 agents
Estimated speedup: 20-30% vs sequential
```

## Configuration Reference

```yaml
claude_code:
  orchestration:
    max_parallel: 3              # Max concurrent agents per wave
    conflict_resolution: queue   # How to handle file conflicts
    timeout_per_agent: 300000    # 5 min timeout per agent (ms)
    retry_on_failure: 1          # Retry failed agents once
    role_isolation: true         # Isolate agent outputs
    wave_overlap:
      enabled: true              # Start next wave at threshold
      skip_flag: "--sequential"  # Flag to disable overlap
      overlap_threshold: 0.80    # 80% completion triggers next wave
      critical_deps_only: true   # Only wait for critical path deps
```

## Wave Status Tracking

During execution, maintain and display wave progress:

### Status Format (per wave)

```text
ğŸŒŠ Wave {N}/{TOTAL} - {WAVE_NAME}
â”œâ”€â”€ Model: {DEFAULT_MODEL} (ultrathink: {ON|OFF})
â”œâ”€â”€ Agents: {COMPLETED}/{TOTAL} ({PERCENTAGE}%)
â”œâ”€â”€ Status: {RUNNING|COMPLETE|BLOCKED}
â”‚
â”œâ”€â”€ âœ“ {agent1} [{model}]: {status} ({duration}s)
â”œâ”€â”€ âœ“ {agent2} [{model}]: {status} ({duration}s)
â”œâ”€â”€ â³ {agent3} [{model}]: in progress...
â””â”€â”€ â¸ {agent4} [{model}]: waiting for deps
```

### Completion Summary

```text
ğŸ“Š Orchestration Complete
â”œâ”€â”€ Total Waves: {N}
â”œâ”€â”€ Total Agents: {M}
â”œâ”€â”€ Execution Time: {TOTAL_TIME}s
â”œâ”€â”€ Parallelism Achieved: {PARALLEL_RATIO}x
â”‚
â”œâ”€â”€ Model Usage:
â”‚   â”œâ”€â”€ haiku: {count} agents ({cost_pct}%)
â”‚   â”œâ”€â”€ sonnet: {count} agents ({cost_pct}%)
â”‚   â””â”€â”€ opus: {count} agents ({cost_pct}%)
â”‚
â”œâ”€â”€ Wave Timing:
â”‚   â”œâ”€â”€ Wave 1: {time}s ({agents} agents)
â”‚   â”œâ”€â”€ Wave 2: {time}s ({agents} agents)
â”‚   â””â”€â”€ Wave N: {time}s ({agents} agents)
â”‚
â””â”€â”€ Estimated Savings: {SAVINGS}% vs sequential
```

### Error Recovery in Ultrathink Mode

When ultrathink mode is active and an agent fails:

```text
IF ULTRATHINK_MODE AND agent.failed:
  # Extended recovery with deep reasoning
  1. Analyze failure root cause with extended thinking
  2. Check if dependencies produced valid output
  3. Attempt retry with increased thinking_budget (+50%)
  4. If retry fails, mark dependents as BLOCKED
  5. Report detailed failure analysis
```

### Live Progress (Background Agents)

For long-running waves with `run_in_background: true`:

```text
EVERY 30 seconds:
  CHECK TaskOutput(agent_id, block=false)
  UPDATE wave status display
  IF wave >= 80% complete AND wave_overlap.enabled:
    TRIGGER next wave start
```

---

## Streaming Output

> **Purpose**: Provide real-time visibility into parallel agent execution. Claude doesn't support true mid-message streaming, so we use **checkpoint-based output** â€” emitting new progress sections after each significant event.

### Streaming Configuration

```yaml
streaming:
  enabled: true                    # Enable streaming output
  checkpoint_on: agent_complete    # Emit after each agent finishes
  show_progress_bar: true          # Visual progress indicator
  show_running_metrics: true       # Time, tokens, cost
  collapse_completed_waves: true   # Minimize finished waves
```

### Checkpoint Trigger Events

| Event | Action |
|-------|--------|
| Wave start | Emit wave header with agent list |
| Agent complete | Update wave display with âœ“/âœ— status |
| Wave 80% threshold | Announce overlap trigger (if enabled) |
| Wave complete | Emit summary, collapse wave |
| All waves complete | Emit final orchestration report |

### Streaming Output Format

```text
FUNCTION emit_wave_progress(wave, agents_status, metrics):

  # Progress bar calculation
  completed = count(agents_status WHERE status IN ["success", "failed"])
  total = len(wave.agents)
  pct = (completed / total) * 100
  bar_filled = floor(pct / 5)  # 20 chars total
  bar_empty = 20 - bar_filled

  PRINT "
ğŸŒŠ Wave {wave.index}/{TOTAL_WAVES} - {wave.name}
â”œâ”€â”€ Progress: [{'â–ˆ' * bar_filled}{'â–‘' * bar_empty}] {pct:.0f}%
â”œâ”€â”€ Agents: {completed}/{total}
â”œâ”€â”€ Elapsed: {metrics.elapsed}s | Tokens: {metrics.tokens_total:,}
â”‚"

  FOR agent IN wave.agents:
    status = agents_status[agent.role]
    IF status.state == "success":
      PRINT "â”œâ”€â”€ âœ“ {agent.role} [{status.model}]: {status.duration}s"
    ELIF status.state == "failed":
      PRINT "â”œâ”€â”€ âœ— {agent.role} [{status.model}]: {status.error}"
    ELIF status.state == "running":
      PRINT "â”œâ”€â”€ â³ {agent.role} [{status.model}]: running..."
    ELSE:
      PRINT "â”œâ”€â”€ â¸ {agent.role}: waiting"

  IF wave.overlap_triggered:
    PRINT "â”‚"
    PRINT "â””â”€â”€ ğŸš€ Overlap threshold reached â€” Wave {wave.index + 1} started early"
```

### Live Metrics Tracking

```text
METRICS_STATE = {
  start_time: timestamp(),
  tokens_in: 0,
  tokens_out: 0,
  cost_estimate: 0.0,
  agents_completed: 0,
  agents_failed: 0
}

FUNCTION update_metrics(agent_result):
  METRICS_STATE.tokens_in += agent_result.tokens_in
  METRICS_STATE.tokens_out += agent_result.tokens_out
  METRICS_STATE.cost_estimate += calculate_cost(agent_result)

  IF agent_result.success:
    METRICS_STATE.agents_completed += 1
  ELSE:
    METRICS_STATE.agents_failed += 1

FUNCTION calculate_cost(result):
  RATES = {
    haiku: {input: 0.25, output: 1.25},    # per 1M tokens
    sonnet: {input: 3.00, output: 15.00},
    opus: {input: 15.00, output: 75.00}
  }
  rate = RATES[result.model_used]
  RETURN (result.tokens_in * rate.input + result.tokens_out * rate.output) / 1_000_000
```

### Execution Loop with Streaming

```text
FUNCTION execute_wave_with_streaming(wave):

  # 1. Emit wave start
  emit_wave_header(wave)

  # 2. Launch all agents in parallel (single message with multiple Task calls)
  agent_tasks = launch_parallel_agents(wave.agents)

  # 3. Collect results as they complete
  agents_status = {}
  FOR agent IN wave.agents:
    agents_status[agent.role] = {state: "running", model: agent.model}

  WHILE NOT all_complete(agent_tasks):

    # Check for completed agents (non-blocking)
    FOR task IN agent_tasks:
      IF task.completed AND task.role NOT IN agents_status.completed:
        result = get_task_result(task)
        update_metrics(result)
        agents_status[task.role] = {
          state: "success" IF result.success ELSE "failed",
          duration: result.duration_ms / 1000,
          model: result.model_used,
          error: result.error
        }

        # CHECKPOINT: Emit updated progress
        emit_wave_progress(wave, agents_status, METRICS_STATE)

    # Check overlap threshold
    IF wave_overlap.enabled AND wave.completion_ratio >= 0.80:
      IF NOT wave.overlap_triggered:
        wave.overlap_triggered = true
        LOG "ğŸš€ Starting Wave {wave.index + 1} early (80% threshold)"
        # Next wave will be started by orchestrator

  # 4. Emit wave completion summary
  emit_wave_complete(wave, agents_status, METRICS_STATE)
```

### Collapsed Wave Format (After Completion)

After a wave completes, collapse it to save screen space:

```text
<details>
<summary>âœ… Wave {N} Complete â€” {agent_count} agents, {duration}s, ${cost:.3f}</summary>

| Agent | Model | Duration | Status |
|-------|-------|----------|--------|
| {role1} | haiku | 12s | âœ“ |
| {role2} | sonnet | 34s | âœ“ |
| {role3} | opus | 45s | âœ“ |

</details>
```

### Skip Flag

```text
IF "--no-streaming" IN ARGS OR "--quiet" IN ARGS:
  streaming.enabled = false
  LOG "ğŸ“´ Streaming output disabled"
  # Fall back to batch-mode reporting (existing behavior)
```

---

## Operation Batching

> **Purpose**: Batch independent operations (file reads, searches, validations) into parallel calls within a **single message**, reducing API round-trips across all commands.

### Batching Hierarchy

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Level 0: Operation Batching (cross-command)                     â”‚
â”‚   - Context reads: batch file reads before processing           â”‚
â”‚   - Searches: batch Explore agents                              â”‚
â”‚   - Validations: batch QG/inline gate checks                    â”‚
â”‚   - Controlled by: operation_batching.strategies                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Level 1: Wave Parallelism (subagent-level)                      â”‚
â”‚   - Agents in same wave execute in parallel                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Level 2: Task Batching (task-level, implement.md only)          â”‚
â”‚   - Tasks grouped by dependencies                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

```yaml
operation_batching:
  enabled: true
  skip_flag: "--sequential"
  framework: templates/shared/operation-batching.md
  strategies:
    context_reads: true    # Batch file reads
    searches: true         # Batch Explore agents
    validations: true      # Batch QG checks
    prefetch: true         # Speculative parallel load
```

### Core Algorithms

#### CONTEXT_BATCH

```text
# Batch multiple file reads
CONTEXT = CONTEXT_BATCH([
  "memory/constitution.md",
  "templates/spec-template.md",
  "{FEATURE_DIR}/spec.md"
])

# Result: Single message with multiple Read calls â†’ 3x faster
```

#### SEARCH_BATCH

```text
# Batch multiple searches
RESULTS = SEARCH_BATCH([
  "Find architecture patterns in codebase",
  "Search for existing API patterns",
  "Find database schema patterns"
])

# Result: Single message with multiple Explore agents â†’ 3x faster
```

#### VALIDATE_BATCH

```text
# Batch inline gate checks
VALIDATION = VALIDATE_BATCH([
  {id: "IG-SPEC-001", check: constitution_alignment},
  {id: "IG-SPEC-002", check: ambiguity_detection},
  {id: "IG-SPEC-003", check: fr_as_coverage}
])

# Result: Parallel validation â†’ faster gate checking
```

### Command-Specific Batching

| Command | Batching Strategy |
|---------|-------------------|
| `/speckit.specify` | Context reads + prefetch |
| `/speckit.plan` | Context reads + research searches |
| `/speckit.tasks` | Context reads + parallel mappers |
| `/speckit.clarify` | Gap search batch |
| `/speckit.design` | Design context pre-cache |
| `/speckit.implement` | Task-level batching (see below) |

### Performance Impact

| Mode | Round-trips | Savings |
|------|-------------|---------|
| Sequential reads (4 files) | 4 | baseline |
| Batched reads (4 files) | 1 | 4x faster |
| Sequential searches (3 queries) | 3 | baseline |
| Batched searches (3 queries) | 1 | 3x faster |

### Skip Flag

```text
IF "--sequential" IN ARGS:
  operation_batching.enabled = false
  LOG "âš ï¸ Operation batching DISABLED (sequential mode)"
```

See `templates/shared/operation-batching.md` for full framework.

---

## Task-Level Batching

> **Purpose**: While subagent-level parallelism executes agents within waves in parallel, **task-level batching** groups individual tasks from tasks.md into batches and executes them as parallel Task tool calls in a **single message**, achieving maximum parallelism.

### Parallelism Hierarchy

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Level 1: Wave Parallelism (subagent-level)                     â”‚
â”‚   - Agents in same wave execute in parallel                    â”‚
â”‚   - Sequential across waves (Wave 1 â†’ Wave 2 â†’ ...)            â”‚
â”‚   - Controlled by: orchestration.max_parallel                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Level 2: Task Batching (task-level) â† NEW                      â”‚
â”‚   - Tasks within agent execution grouped by dependencies       â”‚
â”‚   - Independent tasks â†’ single message with multiple Task callsâ”‚
â”‚   - Controlled by: orchestration.task_batching                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

```yaml
task_batching:
  enabled: true
  skip_flag: "--sequential-tasks"
  max_batch_size: 8                     # Max tasks per batch
  batch_by: dependency_level            # Topological grouping
  file_conflict_resolution: queue       # Same-file â†’ next batch
```

### Integration with Subagent Execution

When a subagent receives tasks to execute:

```text
FUNCTION execute_subagent_with_batching(agent, tasks):

  IF NOT task_batching.enabled OR "--sequential-tasks" IN ARGS:
    # Fallback: sequential execution
    FOR task IN tasks:
      execute_task(task)
    RETURN

  # Apply batching
  batches = BATCH_TASKS(tasks)

  LOG "ğŸ“¦ Batching: {len(tasks)} tasks â†’ {len(batches)} batches"

  FOR batch IN batches:
    # CRITICAL: All Task calls in SINGLE message
    results = EXECUTE_BATCH_PARALLEL(batch)
    update_tasks_md(results)
```

### Performance Impact

| Mode | Round-trips | Time | Savings |
|------|-------------|------|---------|
| Sequential tasks | N (per task) | ~10 min | baseline |
| Batched (4-8 per batch) | N/4-8 | ~2-3 min | 60-75% |

### Batching Algorithm Summary

1. **Parse tasks.md** â†’ extract task IDs, dependencies, target files
2. **Build dependency graph** â†’ topological sort
3. **Group by level** â†’ tasks at same level are independent
4. **Split by file conflicts** â†’ same-file tasks in different batches
5. **Execute batches** â†’ parallel Task calls per batch

See `templates/shared/implement/task-batching.md` for full algorithm.

### Batch Output Format

```text
ğŸ“¦ Batch 1/4 (3 tasks)
â”œâ”€â”€ T001 [haiku]: Create project scaffold
â”œâ”€â”€ T002 [haiku]: Install dependencies
â””â”€â”€ T003 [sonnet]: Configure database

â³ Executing batch in parallel...

âœ“ Batch 1/4 complete (2.3s)
â”œâ”€â”€ âœ“ T001: Created 5 files
â”œâ”€â”€ âœ“ T002: Installed 12 packages
â””â”€â”€ âœ“ T003: Configured PostgreSQL
```

### Skip Flag

```text
IF "--sequential-tasks" IN ARGS:
  task_batching.enabled = false
  LOG "âš ï¸ Task batching DISABLED (sequential mode)"
```
